{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SFT Training on MATH Dataset with Qwen3-4B\n",
    "\n",
    "This notebook demonstrates the impact of Supervised Fine-Tuning (SFT) on math reasoning by:\n",
    "1. Evaluating the base Qwen3-4B model (zero-shot)\n",
    "2. Fine-tuning on MATH training data\n",
    "3. Evaluating the fine-tuned model\n",
    "4. Comparing results to see the improvement\n",
    "\n",
    "**Default Model: Qwen/Qwen3-4B** (4B params, ~8GB)\n",
    "\n",
    "**Other Supported Models:**\n",
    "- Qwen/Qwen2.5-Math-1.5B (1.5B params, ~3GB) - optimized for math\n",
    "- Qwen/Qwen2.5-0.5B (0.5B params, ~1GB) - for testing\n",
    "- Qwen/Qwen3-1.7B (1.7B params, ~4GB) - smaller Qwen3 variant\n",
    "- meta-llama/Llama-3.1-8B (8B params, ~16GB) - requires HuggingFace login\n",
    "\n",
    "**Requirements:**\n",
    "- GPU runtime (A100 recommended for Qwen3-4B)\n",
    "- ~24GB+ GPU memory for Qwen3-4B\n",
    "- ~16GB+ GPU memory for Qwen 1.5B models\n",
    "\n",
    "**Before running:**\n",
    "1. Go to Runtime → Change runtime type → Select GPU (A100 if available)\n",
    "2. For Llama models: Login to HuggingFace (see Section 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/bearbearyu1223/assignment5-alignment.git\n",
    "%cd assignment5-alignment\n",
    "!git checkout han/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv (fast Python package manager)\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add uv to PATH for this session\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.path.expanduser('~')}/.local/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (without flash-attn to avoid build issues)\n",
    "!uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MATH dataset\n",
    "!uv run python scripts/download_math.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify data is downloaded\n",
    "!head -2 data/math/train.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Download Model\n",
    "\n",
    "**Default: Qwen3-4B** - Latest Qwen3 architecture with 4B parameters.\n",
    "\n",
    "### Alternative Models (Optional)\n",
    "- Qwen2.5-Math-1.5B: Smaller, optimized for math\n",
    "- Qwen2.5-0.5B: For quick testing\n",
    "- Llama-3.1-8B: Requires HuggingFace login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available models\n",
    "!uv run python scripts/download_model.py --list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Qwen3-4B (default, ~8GB)\n",
    "!uv run python scripts/download_model.py --model-name Qwen/Qwen3-4B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Download smaller model (uncomment if needed)\n",
    "# !uv run python scripts/download_model.py --model-name Qwen/Qwen2.5-Math-1.5B\n",
    "\n",
    "# Alternative: Download Llama (requires HuggingFace login first)\n",
    "# from huggingface_hub import login\n",
    "# login()  # This will prompt for your HF token\n",
    "# !uv run python scripts/download_model.py --model-name meta-llama/Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Base Model (Zero-Shot)\n",
    "\n",
    "First, let's evaluate the base Qwen3-4B model on 100 MATH test examples to establish a baseline.\n",
    "This shows the model's performance **before** fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base Qwen3-4B model (zero-shot) on 100 test examples\n",
    "!uv run python scripts/run_math_eval.py \\\n",
    "    --model-name-or-path models/qwen3-4b \\\n",
    "    --output-path outputs/qwen3_base_eval.jsonl \\\n",
    "    --backend transformers \\\n",
    "    --num-samples 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show base model accuracy\n",
    "import json\n",
    "with open('outputs/qwen3_base_eval.jsonl') as f:\n",
    "    results = [json.loads(line) for line in f]\n",
    "correct = sum(1 for r in results if r.get('metrics', {}).get('answer_reward', 0) == 1.0)\n",
    "total = len(results)\n",
    "base_accuracy = correct / total * 100\n",
    "print(f\"Base Qwen3-4B Accuracy (Zero-Shot): {correct}/{total} = {base_accuracy:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Fine-Tune with SFT (100 Training Examples)\n",
    "\n",
    "Now let's fine-tune the model on 100 MATH training examples to see the impact of SFT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune Qwen3-4B on 100 training examples\n",
    "!uv run python scripts/run_sft.py --auto \\\n",
    "    --model-name-or-path models/qwen3-4b \\\n",
    "    --train-data-path data/math/train.jsonl \\\n",
    "    --output-dir outputs/sft_qwen3_100 \\\n",
    "    --num-samples 100 \\\n",
    "    --num-epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "display(Image(filename='outputs/sft_qwen3_100/training_curves.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View training metrics\n",
    "import json\n",
    "with open('outputs/sft_qwen3_100/training_metrics.json') as f:\n",
    "    metrics = json.load(f)\n",
    "print(f\"Initial loss: {metrics['losses'][0]:.4f}\")\n",
    "print(f\"Final loss: {metrics['losses'][-1]:.4f}\")\n",
    "print(f\"Total steps: {len(metrics['steps'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluate Fine-Tuned Model\n",
    "\n",
    "Now let's evaluate the fine-tuned model on the same 100 test examples to measure the improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fine-tuned model on 100 test examples\n",
    "!uv run python scripts/run_math_eval.py \\\n",
    "    --model-name-or-path outputs/sft_qwen3_100/final \\\n",
    "    --output-path outputs/qwen3_sft_eval.jsonl \\\n",
    "    --backend transformers \\\n",
    "    --num-samples 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare Results: Before vs After SFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare base vs fine-tuned model accuracy\n",
    "import json\n",
    "\n",
    "# Load base model results\n",
    "with open('outputs/qwen3_base_eval.jsonl') as f:\n",
    "    base_results = [json.loads(line) for line in f]\n",
    "base_correct = sum(1 for r in base_results if r.get('metrics', {}).get('answer_reward', 0) == 1.0)\n",
    "base_total = len(base_results)\n",
    "base_accuracy = base_correct / base_total * 100\n",
    "\n",
    "# Load fine-tuned model results\n",
    "with open('outputs/qwen3_sft_eval.jsonl') as f:\n",
    "    sft_results = [json.loads(line) for line in f]\n",
    "sft_correct = sum(1 for r in sft_results if r.get('metrics', {}).get('answer_reward', 0) == 1.0)\n",
    "sft_total = len(sft_results)\n",
    "sft_accuracy = sft_correct / sft_total * 100\n",
    "\n",
    "# Display comparison\n",
    "print(\"=\" * 50)\n",
    "print(\"MATH Evaluation Results (100 test examples)\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Base Qwen3-4B (Zero-Shot): {base_correct}/{base_total} = {base_accuracy:.1f}%\")\n",
    "print(f\"Fine-Tuned Qwen3-4B (SFT): {sft_correct}/{sft_total} = {sft_accuracy:.1f}%\")\n",
    "print(\"-\" * 50)\n",
    "improvement = sft_accuracy - base_accuracy\n",
    "print(f\"Improvement: {improvement:+.1f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Full Training and Evaluation (Optional)\n",
    "\n",
    "For production use, train on the full MATH dataset and evaluate on all test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training on entire MATH dataset (uncomment when ready)\n",
    "# This will take several hours depending on GPU\n",
    "\n",
    "# !uv run python scripts/run_sft.py --auto \\\n",
    "#     --model-name-or-path models/qwen3-4b \\\n",
    "#     --train-data-path data/math/train.jsonl \\\n",
    "#     --output-dir outputs/sft_qwen3_full \\\n",
    "#     --num-epochs 1 \\\n",
    "#     --learning-rate 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full evaluation on all test examples (uncomment after full training)\n",
    "# !uv run python scripts/run_math_eval.py \\\n",
    "#     --model-name-or-path outputs/sft_qwen3_full/final \\\n",
    "#     --output-path outputs/qwen3_sft_full_eval.jsonl \\\n",
    "#     --backend transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Save Model to Google Drive (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy trained model to Drive\n",
    "!cp -r outputs/sft_qwen3_100/final /content/drive/MyDrive/sft_qwen3_math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Multi-GPU Training (Lambda Labs / Cloud)\n",
    "\n",
    "For faster training with multiple GPUs, use `accelerate launch`:\n",
    "\n",
    "### Quick Setup on Lambda Labs\n",
    "\n",
    "```bash\n",
    "# SSH into your Lambda instance\n",
    "ssh ubuntu@your-instance-ip\n",
    "\n",
    "# Clone and setup\n",
    "git clone https://github.com/bearbearyu1223/assignment5-alignment.git\n",
    "cd assignment5-alignment\n",
    "git checkout han/dev\n",
    "\n",
    "# Install uv\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# source ~/.local/bin/env\n",
    "\n",
    "# Install with CUDA support\n",
    "# uv sync --extra cuda\n",
    "\n",
    "# Download model and data\n",
    "uv run python scripts/download_model.py --model-name Qwen/Qwen3-1.7B\n",
    "uv run python scripts/download_math.py\n",
    "\n",
    "# Run with AUTO mode (auto-detects GPUs and optimal settings)\n",
    "uv run accelerate launch --multi_gpu scripts/run_sft.py --auto \\\n",
    "    --model-name-or-path models/qwen3-1.7b \\\n",
    "    --train-data-path data/math/train.jsonl \\\n",
    "    --output-dir outputs/sft_qwen3 \n",
    "\n",
    "# Evaluate the trained model\n",
    "uv run python scripts/run_math_eval.py \\\n",
    "    --model-name-or-path outputs/sft_qwen3/final \\\n",
    "    --output-path outputs/sft_qwen3_eval.jsonl \n",
    "```\n",
    "\n",
    "### Scaling Guide\n",
    "\n",
    "| Model | GPUs | batch_size | grad_accum | Effective Batch | VRAM/GPU |\n",
    "|-------|------|------------|------------|-----------------|----------|\n",
    "| Qwen3-4B | 1 | 2 | 8 | 16 | ~24GB |\n",
    "| Qwen3-4B | 2 | 2 | 4 | 16 | ~24GB |\n",
    "| Qwen3-4B | 4 | 4 | 1 | 16 | ~24GB |\n",
    "| Qwen 1.5B | 1 | 4 | 4 | 16 | ~16GB |\n",
    "| Llama 8B | 1 | 1 | 8 | 8 | ~40GB |"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
